{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 1105687,
          "sourceType": "datasetVersion",
          "datasetId": 619181
        }
      ],
      "dockerImageVersionId": 30197,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## [1. Import Needed Modules](#import) ##\n",
        "## [2. Read in images and create a dataframe of image paths and class labels](#makedf) ##\n",
        "## [3. Balance the train_df dataframe using trim function](#trim) ##\n",
        "## [4. Create train, test and validation generators](#generators) ##\n",
        "## [5. Create a function to show Training Image Samples](#show) ##\n",
        "## [6. Create the Model](#model) ##\n",
        "## [7. Create a custom Keras callback to continue or halt training](#callback) ##\n",
        "## [8. Instantiate custom callback and create callbacks to control learning rate and early stopping](#callbacks) ##\n",
        "## [9. Train the model](#train) ##\n",
        "## [10. Define a function to plot the training data](#plot) ##\n",
        "## [11. Make predictions on test set, create Confusion Matrix and Classification Report](#result) ##\n",
        "## [12 Save the model](#save) ##\n",
        "## [13 Analysis of Model Results](#results) ##\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JpWkqT0IUdZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"import\"></a>\n",
        "# <center>Import Need Modules</center>"
      ],
      "metadata": {
        "id": "mZSBAvcQUdZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT5Ax_CgEWGd",
        "outputId": "d29cae29-5e0e-4622-c6ba-bb99d6ea36c9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyunpack\n",
        "!pip install patool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofr_AaOTz5lH",
        "outputId": "bb7da608-0cae-4831-f3c1-420fc4b43f9f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyunpack\n",
            "  Downloading pyunpack-0.3-py2.py3-none-any.whl (4.1 kB)\n",
            "Collecting easyprocess (from pyunpack)\n",
            "  Downloading EasyProcess-1.1-py3-none-any.whl (8.7 kB)\n",
            "Collecting entrypoint2 (from pyunpack)\n",
            "  Downloading entrypoint2-1.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Installing collected packages: entrypoint2, easyprocess, pyunpack\n",
            "Successfully installed easyprocess-1.1 entrypoint2-1.1 pyunpack-0.3\n",
            "Collecting patool\n",
            "  Downloading patool-2.2.0-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from pyunpack import Archive\n",
        "#Archive('/content/drive/MyDrive/Chicken_Disease_Dataset2.rar').extractall('/content/drive/MyDrive')"
      ],
      "metadata": {
        "id": "enpEwlV1z5nz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Im154p7bz5pv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "import shutil\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os, requests, cv2, random\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import Sequential, layers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-24T08:11:40.966728Z",
          "iopub.execute_input": "2022-08-24T08:11:40.967588Z",
          "iopub.status.idle": "2022-08-24T08:11:46.827989Z",
          "shell.execute_reply.started": "2022-08-24T08:11:40.9675Z",
          "shell.execute_reply": "2022-08-24T08:11:46.827149Z"
        },
        "trusted": true,
        "id": "Tj2h5xqGUdZX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"makedf\"></a>\n",
        "# <center>Read in images and create a dataframe of image paths and class labels</center>\n"
      ],
      "metadata": {
        "id": "Gcx2XMMUUdZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir=r'/content/drive/MyDrive/Chicken_Disease_Dataset3/train'\n",
        "valid_dir=r'/content/drive/MyDrive/Chicken_Disease_Dataset3/val'\n",
        "for d in [train_dir, valid_dir]:\n",
        "    filepaths = []\n",
        "    labels=[]\n",
        "    classlist=sorted(os.listdir(d))\n",
        "    for klass in classlist:\n",
        "        label=klass.split('__')[0]\n",
        "        classpath=os.path.join(d, klass)\n",
        "        flist=sorted(os.listdir(classpath))\n",
        "        for f in flist:\n",
        "            fpath=os.path.join(classpath,f)\n",
        "            filepaths.append(fpath)\n",
        "            labels.append(label)\n",
        "    Fseries=pd.Series(filepaths, name='filepaths')\n",
        "    Lseries=pd.Series(labels, name='labels')\n",
        "    if d == train_dir:\n",
        "        df=pd.concat([Fseries, Lseries], axis=1)\n",
        "    else:\n",
        "        test_df=pd.concat([Fseries, Lseries], axis=1)\n",
        "train_df, valid_df=train_test_split(df, train_size=.8, shuffle=True, random_state=123, stratify=df['labels'])\n",
        "print('train_df lenght: ', len(train_df), '  test_df length: ', len(test_df), '  valid_df length: ', len(valid_df))\n",
        "# get the number of classes and the images count for each class in train_df\n",
        "classes=sorted(list(train_df['labels'].unique()))\n",
        "class_count = len(classes)\n",
        "print('The number of classes in the dataset is: ', class_count)\n",
        "groups=train_df.groupby('labels')\n",
        "print('{0:^30s} {1:^13s}'.format('CLASS', 'IMAGE COUNT'))\n",
        "countlist=[]\n",
        "classlist=[]\n",
        "for label in sorted(list(train_df['labels'].unique())):\n",
        "    group=groups.get_group(label)\n",
        "    countlist.append(len(group))\n",
        "    classlist.append(label)\n",
        "    print('{0:^30s} {1:^13s}'.format(label, str(len(group))))\n",
        "\n",
        "# get the classes with the minimum and maximum number of train images\n",
        "max_value=np.max(countlist)\n",
        "max_index=countlist.index(max_value)\n",
        "max_class=classlist[max_index]\n",
        "min_value=np.min(countlist)\n",
        "min_index=countlist.index(min_value)\n",
        "min_class=classlist[min_index]\n",
        "print(max_class, ' has the most images= ',max_value, ' ', min_class, ' has the least images= ', min_value)\n",
        "# lets get the average height and width of a sample of the train images\n",
        "ht=0\n",
        "wt=0\n",
        "# select 100 random samples of train_df\n",
        "train_df_sample=train_df.sample(n=100, random_state=123,axis=0)\n",
        "for i in range (len(train_df_sample)):\n",
        "    fpath=train_df_sample['filepaths'].iloc[i]\n",
        "    img=plt.imread(fpath)\n",
        "    shape=img.shape\n",
        "    ht += shape[0]\n",
        "    wt += shape[1]\n",
        "print('average height= ', ht//100, ' average width= ', wt//100, 'aspect ratio= ', ht/wt)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-24T08:16:53.126952Z",
          "iopub.execute_input": "2022-08-24T08:16:53.12833Z",
          "iopub.status.idle": "2022-08-24T08:16:54.349237Z",
          "shell.execute_reply.started": "2022-08-24T08:16:53.128284Z",
          "shell.execute_reply": "2022-08-24T08:16:54.348342Z"
        },
        "trusted": true,
        "id": "6BHVwi8KUdZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0407893c-3d4f-4940-9cf9-b4733bfbe86e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_df lenght:  10329   test_df length:  1726   valid_df length:  2583\n",
            "The number of classes in the dataset is:  4\n",
            "            CLASS               IMAGE COUNT \n",
            "         Coccidiosis               2664     \n",
            "           Healthy                 2584     \n",
            "      New Castle Disease           2277     \n",
            "          Salmonella               2804     \n",
            "Salmonella  has the most images=  2804   New Castle Disease  has the least images=  2277\n",
            "average height=  224  average width=  224 aspect ratio=  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"trim\"></a>\n",
        "# <center>Trim the dataset to balance he class samples</center>\n",
        "### The trim function defined below takes in a dataframe and integers max_samples and min_samples plus\n",
        "### a column name. It returns a dataframe where each class have no more than max_samples images in\n",
        "### any class. If a class has less than min_samples images the class is excluded from the dataframe."
      ],
      "metadata": {
        "id": "XhEZFMDYUdZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trim(df, max_samples, min_samples, column):\n",
        "    df=df.copy()\n",
        "    groups=df.groupby(column)\n",
        "    trimmed_df = pd.DataFrame(columns = df.columns)\n",
        "    groups=df.groupby(column)\n",
        "    for label in df[column].unique():\n",
        "        group=groups.get_group(label)\n",
        "        count=len(group)\n",
        "        if count > max_samples:\n",
        "            sampled_group=group.sample(n=max_samples, random_state=123,axis=0)\n",
        "            trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n",
        "        else:\n",
        "            if count>=min_samples:\n",
        "                sampled_group=group\n",
        "                trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n",
        "    print('after trimming, the maximum samples in any class is now ',max_samples, ' and the minimum samples in any class is ', min_samples)\n",
        "    return trimmed_df\n",
        "\n",
        "max_samples=2000 # since each class has more than 200 images all classes will be trimmed to have 200 images per class\n",
        "min_samples=2000\n",
        "column='labels'\n",
        "train_df= trim(train_df, max_samples, min_samples, column)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-24T08:16:59.627433Z",
          "iopub.execute_input": "2022-08-24T08:16:59.627819Z",
          "iopub.status.idle": "2022-08-24T08:16:59.658194Z",
          "shell.execute_reply.started": "2022-08-24T08:16:59.627788Z",
          "shell.execute_reply": "2022-08-24T08:16:59.657317Z"
        },
        "trusted": true,
        "id": "iTGAB84CUdZZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b3f679c-74f1-4f7f-ff9f-a4d2914fe7fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after trimming, the maximum samples in any class is now  2000  and the minimum samples in any class is  2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"generators\"></a>\n",
        "# <center>Create the train_gen, test_gen final_test_gen and valid_gen</center>"
      ],
      "metadata": {
        "id": "VD0y98GCUdZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "working_dir=r'./'\n",
        "img_size=(224,224)\n",
        "batch_size=64 # We will use and EfficientetB3 model, with image size of (200, 250) this size should not cause resource error\n",
        "trgen=ImageDataGenerator(horizontal_flip=True,rotation_range=20, width_shift_range=.2,\n",
        "                                  height_shift_range=.2, zoom_range=.2 )\n",
        "t_and_v_gen=ImageDataGenerator()\n",
        "msg='{0:70s} for train generator'.format(' ')\n",
        "print(msg, '\\r', end='') # prints over on the same line\n",
        "train_gen=trgen.flow_from_dataframe(train_df, x_col='filepaths', y_col='labels', target_size=img_size,\n",
        "                                   class_mode='categorical', color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
        "msg='{0:70s} for valid generator'.format(' ')\n",
        "print(msg, '\\r', end='') # prints over on the same line\n",
        "valid_gen=t_and_v_gen.flow_from_dataframe(valid_df, x_col='filepaths', y_col='labels', target_size=img_size,\n",
        "                                   class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=batch_size)\n",
        "# for the test_gen we want to calculate the batch size and test steps such that batch_size X test_steps= number of samples in test set\n",
        "# this insures that we go through all the sample in the test set exactly once.\n",
        "length=len(test_df)\n",
        "test_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]\n",
        "test_steps=int(length/test_batch_size)\n",
        "msg='{0:70s} for test generator'.format(' ')\n",
        "print(msg, '\\r', end='') # prints over on the same line\n",
        "test_gen=t_and_v_gen.flow_from_dataframe(test_df, x_col='filepaths', y_col='labels', target_size=img_size,\n",
        "                                   class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n",
        "# from the generator we can get information we will need later\n",
        "classes=list(train_gen.class_indices.keys())\n",
        "class_indices=list(train_gen.class_indices.values())\n",
        "class_count=len(classes)\n",
        "labels=test_gen.labels\n",
        "print ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps, ' number of classes : ', class_count)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-24T08:17:04.615601Z",
          "iopub.execute_input": "2022-08-24T08:17:04.61644Z",
          "iopub.status.idle": "2022-08-24T08:17:07.247943Z",
          "shell.execute_reply.started": "2022-08-24T08:17:04.616405Z",
          "shell.execute_reply": "2022-08-24T08:17:07.247073Z"
        },
        "trusted": true,
        "id": "pHHQH9AkUdZa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26aa095a-cfbf-4d8f-a97b-4ec230881f91"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 validated image filenames belonging to 4 classes.\n",
            "Found 2583 validated image filenames belonging to 4 classes.\n",
            "Found 1726 validated image filenames belonging to 4 classes.\n",
            "test batch size:  2   test steps:  863  number of classes :  4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"show\"></a>\n",
        "# <center>Create a function to show example training images</center>"
      ],
      "metadata": {
        "id": "gElFulPCUdZa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"model\"></a>\n",
        "# <center>Create a model using transfer learning with EfficientNetB3</center>\n",
        "### NOTE experts advise you make the base model initially not trainable. Then train for some number of epochs\n",
        "### then fine tune model by making base model trainable and run more epochs\n",
        "### I have found this to be WRONG!!!!\n",
        "### Making the base model trainable from the outset leads to faster convegence and a lower validation loss\n",
        "### for the same number of total epochs!"
      ],
      "metadata": {
        "id": "e-N62jr4UdZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN model layers\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "model.add(layers.Conv2D (32, kernel_size = (3,3), activation='relu', input_shape = [224, 224,3])),\n",
        "model.add(layers.MaxPooling2D(pool_size = (2, 2))),\n",
        "\n",
        "model.add(layers.Conv2D(64, (3,3), activation='relu')),\n",
        "model.add(layers. MaxPooling2D((2, 2))),\n",
        "\n",
        "model.add(layers.Conv2D (64, (3,3), activation='relu')),\n",
        "model.add(layers.MaxPooling2D((2, 2))),\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu')),\n",
        "model.add(layers.MaxPooling2D((2, 2))),\n",
        "\n",
        "model.add(layers. Conv2D (64, (3, 3), activation='relu')),\n",
        "model.add(layers.MaxPooling2D((2, 2))),\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu')),\n",
        "model.add(layers.MaxPooling2D((2, 2))),\n",
        "\n",
        "model.add(layers.Flatten()),\n",
        "\n",
        "model.add(layers.Dense(64,activation='relu'))\n",
        "model.add(layers.Dropout(rate=0.5, seed=123))\n",
        "#output layer\n",
        "model.add(layers.Dense(4,activation='softmax'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-24T08:17:41.529821Z",
          "iopub.execute_input": "2022-08-24T08:17:41.53039Z",
          "iopub.status.idle": "2022-08-24T08:17:48.912936Z",
          "shell.execute_reply.started": "2022-08-24T08:17:41.530357Z",
          "shell.execute_reply": "2022-08-24T08:17:48.912053Z"
        },
        "trusted": true,
        "id": "tphR1teqUdZb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xO6UZNu5ks02",
        "outputId": "47857d84-addb-4386-c720-92741d008b1e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 111, 111, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 52, 52, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 26, 26, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 24, 24, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 12, 12, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 10, 10, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 5, 5, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 3, 3, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 1, 1, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 171524 (670.02 KB)\n",
            "Trainable params: 171524 (670.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "metadata": {
        "id": "8_f8DyGlkyQO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "US3kvkVoky3s"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"callback\"></a>\n",
        "# <center>Create a custom Keras callback to continue or halt training</center>"
      ],
      "metadata": {
        "id": "-XodBSmJUdZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ASK(keras.callbacks.Callback):\n",
        "    def __init__ (self, model, epochs,  ask_epoch): # initialization of the callback\n",
        "        super(ASK, self).__init__()\n",
        "        self.model=model\n",
        "        self.ask_epoch=ask_epoch\n",
        "        self.epochs=epochs\n",
        "        self.ask=True # if True query the user on a specified epoch\n",
        "\n",
        "    def on_train_begin(self, logs=None): # this runs on the beginning of training\n",
        "        if self.ask_epoch == 0:\n",
        "            print('you set ask_epoch = 0, ask_epoch will be set to 1', flush=True)\n",
        "            self.ask_epoch=1\n",
        "        if self.ask_epoch >= self.epochs: # you are running for epochs but ask_epoch>epochs\n",
        "            print('ask_epoch >= epochs, will train for ', epochs, ' epochs', flush=True)\n",
        "            self.ask=False # do not query the user\n",
        "        if self.epochs == 1:\n",
        "            self.ask=False # running only for 1 epoch so do not query user\n",
        "        else:\n",
        "            print('Training will proceed until epoch', ask_epoch,' then you will be asked to')\n",
        "            print(' enter H to halt training or enter an integer for how many more epochs to run then be asked again')\n",
        "        self.start_time= time.time() # set the time at which training started\n",
        "\n",
        "    def on_train_end(self, logs=None):   # runs at the end of training\n",
        "        tr_duration=time.time() - self.start_time   # determine how long the training cycle lasted\n",
        "        hours = tr_duration // 3600\n",
        "        minutes = (tr_duration - (hours * 3600)) // 60\n",
        "        seconds = tr_duration - ((hours * 3600) + (minutes * 60))\n",
        "        msg = f'training elapsed time was {str(hours)} hours, {minutes:4.1f} minutes, {seconds:4.2f} seconds)'\n",
        "        print (msg, flush=True) # print out training duration time\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):  # method runs on the end of each epoch\n",
        "        if self.ask: # are the conditions right to query the user?\n",
        "            if epoch + 1 ==self.ask_epoch: # is this epoch the one for quering the user?\n",
        "                print('\\n Enter H to end training or  an integer for the number of additional epochs to run then ask again')\n",
        "                ans=input()\n",
        "\n",
        "                if ans == 'H' or ans =='h' or ans == '0': # quit training for these conditions\n",
        "                    print ('you entered ', ans, ' Training halted on epoch ', epoch+1, ' due to user input\\n', flush=True)\n",
        "                    self.model.stop_training = True # halt training\n",
        "                else: # user wants to continue training\n",
        "                    self.ask_epoch += int(ans)\n",
        "                    if self.ask_epoch > self.epochs:\n",
        "                        print('\\nYou specified maximum epochs of as ', self.epochs, ' cannot train for ', self.ask_epoch, flush =True)\n",
        "                    else:\n",
        "                        print ('you entered ', ans, ' Training will continue to epoch ', self.ask_epoch, flush=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-24T08:17:51.533545Z",
          "iopub.execute_input": "2022-08-24T08:17:51.534061Z",
          "iopub.status.idle": "2022-08-24T08:17:51.55327Z",
          "shell.execute_reply.started": "2022-08-24T08:17:51.534028Z",
          "shell.execute_reply": "2022-08-24T08:17:51.552124Z"
        },
        "trusted": true,
        "id": "W1__EBDsUdZb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"callbacks\"></a>\n",
        "# <center>Instantiate custom callback and create 2 callbacks to control learning rate and early stop"
      ],
      "metadata": {
        "id": "qBnpfREgUdZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=70\n",
        "ask_epoch=50\n",
        "ask=ASK(model, epochs,  ask_epoch)\n",
        "rlronp=tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=2,verbose=1)\n",
        "estop=tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=20, verbose=1,restore_best_weights=True)\n",
        "callbacks=[rlronp, estop, ask]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-24T08:18:04.702546Z",
          "iopub.execute_input": "2022-08-24T08:18:04.703255Z",
          "iopub.status.idle": "2022-08-24T08:18:04.708792Z",
          "shell.execute_reply.started": "2022-08-24T08:18:04.703222Z",
          "shell.execute_reply": "2022-08-24T08:18:04.707634Z"
        },
        "trusted": true,
        "id": "QHxMLO0PUdZc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"train\"></a>\n",
        "# <center>Train the model\n",
        "### Note unlike how you are told it is BETTER to make the base model trainable from the outset\n",
        "### It will converge faster and have a lower validation losss"
      ],
      "metadata": {
        "id": "qFaY3lMOUdZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(x=train_gen,  epochs=epochs, verbose=1, callbacks=callbacks,  validation_data=valid_gen,\n",
        "               validation_steps=None,  shuffle=False,  initial_epoch=0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-08-24T08:18:14.074451Z",
          "iopub.execute_input": "2022-08-24T08:18:14.075039Z",
          "iopub.status.idle": "2022-08-24T08:22:45.178373Z",
          "shell.execute_reply.started": "2022-08-24T08:18:14.075003Z",
          "shell.execute_reply": "2022-08-24T08:22:45.177511Z"
        },
        "trusted": true,
        "id": "6vu4swQCUdZc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea4fce48-390f-4edd-c33c-0707dc1afbc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training will proceed until epoch 50  then you will be asked to\n",
            " enter H to halt training or enter an integer for how many more epochs to run then be asked again\n",
            "Epoch 1/70\n",
            "125/125 [==============================] - 3087s 25s/step - loss: 1.4009 - accuracy: 0.4353 - val_loss: 0.9678 - val_accuracy: 0.5861 - lr: 0.0010\n",
            "Epoch 2/70\n",
            "125/125 [==============================] - 142s 1s/step - loss: 0.9530 - accuracy: 0.6051 - val_loss: 0.9532 - val_accuracy: 0.5772 - lr: 0.0010\n",
            "Epoch 3/70\n",
            "125/125 [==============================] - 137s 1s/step - loss: 0.8502 - accuracy: 0.6556 - val_loss: 0.6570 - val_accuracy: 0.7449 - lr: 0.0010\n",
            "Epoch 4/70\n",
            "125/125 [==============================] - 136s 1s/step - loss: 0.7460 - accuracy: 0.7203 - val_loss: 0.5501 - val_accuracy: 0.8107 - lr: 0.0010\n",
            "Epoch 5/70\n",
            "125/125 [==============================] - 138s 1s/step - loss: 0.6082 - accuracy: 0.7772 - val_loss: 0.5258 - val_accuracy: 0.8029 - lr: 0.0010\n",
            "Epoch 6/70\n",
            "125/125 [==============================] - 138s 1s/step - loss: 0.5675 - accuracy: 0.7997 - val_loss: 0.4679 - val_accuracy: 0.8440 - lr: 0.0010\n",
            "Epoch 7/70\n",
            "125/125 [==============================] - 137s 1s/step - loss: 0.5221 - accuracy: 0.8155 - val_loss: 0.4190 - val_accuracy: 0.8614 - lr: 0.0010\n",
            "Epoch 8/70\n",
            "125/125 [==============================] - 136s 1s/step - loss: 0.4850 - accuracy: 0.8321 - val_loss: 0.4562 - val_accuracy: 0.8467 - lr: 0.0010\n",
            "Epoch 9/70\n",
            "125/125 [==============================] - 138s 1s/step - loss: 0.4601 - accuracy: 0.8389 - val_loss: 0.4082 - val_accuracy: 0.8591 - lr: 0.0010\n",
            "Epoch 10/70\n",
            "125/125 [==============================] - 147s 1s/step - loss: 0.4358 - accuracy: 0.8461 - val_loss: 0.3836 - val_accuracy: 0.8637 - lr: 0.0010\n",
            "Epoch 11/70\n",
            "125/125 [==============================] - 137s 1s/step - loss: 0.4516 - accuracy: 0.8428 - val_loss: 0.4112 - val_accuracy: 0.8610 - lr: 0.0010\n",
            "Epoch 12/70\n",
            "125/125 [==============================] - 135s 1s/step - loss: 0.4382 - accuracy: 0.8474 - val_loss: 0.3468 - val_accuracy: 0.8784 - lr: 0.0010\n",
            "Epoch 13/70\n",
            "125/125 [==============================] - 137s 1s/step - loss: 0.3866 - accuracy: 0.8668 - val_loss: 0.3576 - val_accuracy: 0.8769 - lr: 0.0010\n",
            "Epoch 14/70\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.3867 - accuracy: 0.8611\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "125/125 [==============================] - 138s 1s/step - loss: 0.3867 - accuracy: 0.8611 - val_loss: 0.3650 - val_accuracy: 0.8672 - lr: 0.0010\n",
            "Epoch 15/70\n",
            "125/125 [==============================] - 137s 1s/step - loss: 0.3477 - accuracy: 0.8791 - val_loss: 0.3125 - val_accuracy: 0.8951 - lr: 5.0000e-04\n",
            "Epoch 16/70\n",
            "125/125 [==============================] - 136s 1s/step - loss: 0.3234 - accuracy: 0.8896 - val_loss: 0.2577 - val_accuracy: 0.9102 - lr: 5.0000e-04\n",
            "Epoch 17/70\n",
            "125/125 [==============================] - 146s 1s/step - loss: 0.3057 - accuracy: 0.8974 - val_loss: 0.2933 - val_accuracy: 0.8955 - lr: 5.0000e-04\n",
            "Epoch 18/70\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.3043 - accuracy: 0.8950\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "125/125 [==============================] - 138s 1s/step - loss: 0.3043 - accuracy: 0.8950 - val_loss: 0.3064 - val_accuracy: 0.8943 - lr: 5.0000e-04\n",
            "Epoch 19/70\n",
            "125/125 [==============================] - 138s 1s/step - loss: 0.2803 - accuracy: 0.9043 - val_loss: 0.2385 - val_accuracy: 0.9156 - lr: 2.5000e-04\n",
            "Epoch 20/70\n",
            "125/125 [==============================] - 145s 1s/step - loss: 0.2571 - accuracy: 0.9169 - val_loss: 0.2355 - val_accuracy: 0.9172 - lr: 2.5000e-04\n",
            "Epoch 21/70\n",
            "125/125 [==============================] - 137s 1s/step - loss: 0.2490 - accuracy: 0.9144 - val_loss: 0.2362 - val_accuracy: 0.9148 - lr: 2.5000e-04\n",
            "Epoch 22/70\n",
            "125/125 [==============================] - 138s 1s/step - loss: 0.2473 - accuracy: 0.9158 - val_loss: 0.2129 - val_accuracy: 0.9261 - lr: 2.5000e-04\n",
            "Epoch 23/70\n",
            "125/125 [==============================] - 137s 1s/step - loss: 0.2525 - accuracy: 0.9196 - val_loss: 0.2323 - val_accuracy: 0.9226 - lr: 2.5000e-04\n",
            "Epoch 24/70\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2489 - accuracy: 0.9171\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "125/125 [==============================] - 147s 1s/step - loss: 0.2489 - accuracy: 0.9171 - val_loss: 0.2469 - val_accuracy: 0.9226 - lr: 2.5000e-04\n",
            "Epoch 25/70\n",
            "125/125 [==============================] - 136s 1s/step - loss: 0.2179 - accuracy: 0.9262 - val_loss: 0.2288 - val_accuracy: 0.9218 - lr: 1.2500e-04\n",
            "Epoch 26/70\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.9265\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "125/125 [==============================] - 136s 1s/step - loss: 0.2151 - accuracy: 0.9265 - val_loss: 0.2336 - val_accuracy: 0.9172 - lr: 1.2500e-04\n",
            "Epoch 27/70\n",
            "125/125 [==============================] - 137s 1s/step - loss: 0.2120 - accuracy: 0.9306 - val_loss: 0.2195 - val_accuracy: 0.9241 - lr: 6.2500e-05\n",
            "Epoch 28/70\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2046 - accuracy: 0.9305\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "125/125 [==============================] - 138s 1s/step - loss: 0.2046 - accuracy: 0.9305 - val_loss: 0.2135 - val_accuracy: 0.9280 - lr: 6.2500e-05\n",
            "Epoch 29/70\n",
            "125/125 [==============================] - 135s 1s/step - loss: 0.2009 - accuracy: 0.9346 - val_loss: 0.2081 - val_accuracy: 0.9307 - lr: 3.1250e-05\n",
            "Epoch 30/70\n",
            "125/125 [==============================] - 145s 1s/step - loss: 0.1891 - accuracy: 0.9361 - val_loss: 0.2089 - val_accuracy: 0.9272 - lr: 3.1250e-05\n",
            "Epoch 31/70\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1975 - accuracy: 0.9350\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "125/125 [==============================] - 138s 1s/step - loss: 0.1975 - accuracy: 0.9350 - val_loss: 0.2148 - val_accuracy: 0.9284 - lr: 3.1250e-05\n",
            "Epoch 32/70\n",
            "125/125 [==============================] - 137s 1s/step - loss: 0.1900 - accuracy: 0.9383 - val_loss: 0.2095 - val_accuracy: 0.9307 - lr: 1.5625e-05\n",
            "Epoch 33/70\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.9375\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "125/125 [==============================] - 137s 1s/step - loss: 0.1874 - accuracy: 0.9375 - val_loss: 0.2095 - val_accuracy: 0.9288 - lr: 1.5625e-05\n",
            "Epoch 34/70\n",
            "125/125 [==============================] - 135s 1s/step - loss: 0.1938 - accuracy: 0.9359 - val_loss: 0.2081 - val_accuracy: 0.9292 - lr: 7.8125e-06\n",
            "Epoch 35/70\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1806 - accuracy: 0.9380\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "125/125 [==============================] - 137s 1s/step - loss: 0.1806 - accuracy: 0.9380 - val_loss: 0.2081 - val_accuracy: 0.9299 - lr: 7.8125e-06\n",
            "Epoch 36/70\n",
            "125/125 [==============================] - 136s 1s/step - loss: 0.1900 - accuracy: 0.9365 - val_loss: 0.2066 - val_accuracy: 0.9311 - lr: 3.9063e-06\n",
            "Epoch 37/70\n",
            "125/125 [==============================] - 137s 1s/step - loss: 0.1879 - accuracy: 0.9379 - val_loss: 0.2075 - val_accuracy: 0.9311 - lr: 3.9063e-06\n",
            "Epoch 38/70\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1907 - accuracy: 0.9370\n",
            "Epoch 38: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "125/125 [==============================] - 134s 1s/step - loss: 0.1907 - accuracy: 0.9370 - val_loss: 0.2094 - val_accuracy: 0.9288 - lr: 3.9063e-06\n",
            "Epoch 39/70\n",
            "125/125 [==============================] - 137s 1s/step - loss: 0.1854 - accuracy: 0.9389 - val_loss: 0.2080 - val_accuracy: 0.9299 - lr: 1.9531e-06\n",
            "Epoch 40/70\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1855 - accuracy: 0.9390\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
            "125/125 [==============================] - 137s 1s/step - loss: 0.1855 - accuracy: 0.9390 - val_loss: 0.2079 - val_accuracy: 0.9299 - lr: 1.9531e-06\n",
            "Epoch 41/70\n",
            "125/125 [==============================] - 136s 1s/step - loss: 0.1947 - accuracy: 0.9364 - val_loss: 0.2073 - val_accuracy: 0.9299 - lr: 9.7656e-07\n",
            "Epoch 42/70\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1886 - accuracy: 0.9389\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
            "125/125 [==============================] - 136s 1s/step - loss: 0.1886 - accuracy: 0.9389 - val_loss: 0.2071 - val_accuracy: 0.9295 - lr: 9.7656e-07\n",
            "Epoch 43/70\n",
            "125/125 [==============================] - 136s 1s/step - loss: 0.1898 - accuracy: 0.9370 - val_loss: 0.2068 - val_accuracy: 0.9299 - lr: 4.8828e-07\n",
            "Epoch 44/70\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1891 - accuracy: 0.9361\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
            "125/125 [==============================] - 137s 1s/step - loss: 0.1891 - accuracy: 0.9361 - val_loss: 0.2068 - val_accuracy: 0.9303 - lr: 4.8828e-07\n",
            "Epoch 45/70\n",
            "125/125 [==============================] - 145s 1s/step - loss: 0.1881 - accuracy: 0.9369 - val_loss: 0.2070 - val_accuracy: 0.9299 - lr: 2.4414e-07\n",
            "Epoch 46/70\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1889 - accuracy: 0.9380\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
            "125/125 [==============================] - 145s 1s/step - loss: 0.1889 - accuracy: 0.9380 - val_loss: 0.2071 - val_accuracy: 0.9299 - lr: 2.4414e-07\n",
            "Epoch 47/70\n",
            "125/125 [==============================] - 137s 1s/step - loss: 0.1985 - accuracy: 0.9334 - val_loss: 0.2071 - val_accuracy: 0.9299 - lr: 1.2207e-07\n",
            "Epoch 48/70\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1952 - accuracy: 0.9370\n",
            "Epoch 48: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
            "125/125 [==============================] - 136s 1s/step - loss: 0.1952 - accuracy: 0.9370 - val_loss: 0.2071 - val_accuracy: 0.9299 - lr: 1.2207e-07\n",
            "Epoch 49/70\n",
            "125/125 [==============================] - 137s 1s/step - loss: 0.1806 - accuracy: 0.9404 - val_loss: 0.2071 - val_accuracy: 0.9299 - lr: 6.1035e-08\n",
            "Epoch 50/70\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1814 - accuracy: 0.9384\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
            "\n",
            " Enter H to end training or  an integer for the number of additional epochs to run then ask again\n",
            "5\n",
            "you entered  5  Training will continue to epoch  55\n",
            "125/125 [==============================] - 1219s 10s/step - loss: 0.1814 - accuracy: 0.9384 - val_loss: 0.2071 - val_accuracy: 0.9303 - lr: 6.1035e-08\n",
            "Epoch 51/70\n",
            "125/125 [==============================] - 137s 1s/step - loss: 0.1864 - accuracy: 0.9391 - val_loss: 0.2070 - val_accuracy: 0.9303 - lr: 3.0518e-08\n",
            "Epoch 52/70\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1886 - accuracy: 0.9362\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
            "125/125 [==============================] - 136s 1s/step - loss: 0.1886 - accuracy: 0.9362 - val_loss: 0.2071 - val_accuracy: 0.9303 - lr: 3.0518e-08\n",
            "Epoch 53/70\n",
            "125/125 [==============================] - 138s 1s/step - loss: 0.1918 - accuracy: 0.9344 - val_loss: 0.2071 - val_accuracy: 0.9303 - lr: 1.5259e-08\n",
            "Epoch 54/70\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1840 - accuracy: 0.9361\n",
            "Epoch 54: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
            "125/125 [==============================] - 137s 1s/step - loss: 0.1840 - accuracy: 0.9361 - val_loss: 0.2071 - val_accuracy: 0.9303 - lr: 1.5259e-08\n",
            "Epoch 55/70\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1985 - accuracy: 0.9358\n",
            " Enter H to end training or  an integer for the number of additional epochs to run then ask again\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"plot\"></a>\n",
        "# <center>Define a function to plot the training data"
      ],
      "metadata": {
        "id": "Ktl5StZRUdZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the style to a white background\n",
        "plt.style.use('seaborn-white')\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy',color='green')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'], label='Training Loss',color='green')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss', color='red')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "id9EQYZwmTxK",
        "outputId": "a1824cf4-2835-4016-e392-1317c82a0bbe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-180c42608882>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Set the style to a white background\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'seaborn-white'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Plot training & validation accuracy values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'green'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.figure(figsize=(11, 6))\n",
        "# plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, acc, label='Training Accuracy', linewidth=1.5)\n",
        "plt.plot(epochs, val_acc, label='Validation Accuracy', linewidth=1.5)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.savefig('BN_a_c_Z64_DL256_0.1V.png', bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print()\n",
        "\n",
        "plt.figure(figsize=(11, 6))\n",
        "# plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, loss, label='Training Loss', linewidth=1.5)\n",
        "plt.plot(epochs, val_loss, label='Validation Loss', linewidth=1.5)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "# plt.savefig('loss.png', bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "rUun-SseOFW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(valid_gen)"
      ],
      "metadata": {
        "id": "Ar8Cmlt_h_OF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(train_gen)"
      ],
      "metadata": {
        "id": "V5L7CBw0q0fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"result\"></a>\n",
        "# <center>Make Predictions on the test set</a>\n",
        "### Define a function which takes in a test generator and an integer test_steps\n",
        "### and generates predictions on the test set including a confusion matric\n",
        "### and a classification report"
      ],
      "metadata": {
        "id": "7EuyMyWZUdZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predictor(test_gen, test_steps):\n",
        "    y_pred= []\n",
        "    y_true=test_gen.labels\n",
        "    classes=list(train_gen.class_indices.keys())\n",
        "    class_count=len(classes)\n",
        "    errors=0\n",
        "    preds=model.predict(test_gen, steps=test_steps, verbose=1) # predict on the test set\n",
        "    tests=len(preds)\n",
        "    for i, p in enumerate(preds):\n",
        "            pred_index=np.argmax(p)\n",
        "            true_index=test_gen.labels[i]  # labels are integer values\n",
        "            if pred_index != true_index: # a misclassification has occurred\n",
        "                errors=errors + 1\n",
        "            y_pred.append(pred_index)\n",
        "    acc=( 1-errors/tests) * 100\n",
        "    print(f'there were {errors} in {tests} tests for an accuracy of {acc:6.2f}')\n",
        "    ypred=np.array(y_pred)\n",
        "    ytrue=np.array(y_true)\n",
        "    if class_count <=30:\n",
        "        cm = confusion_matrix(ytrue, ypred )\n",
        "        # plot the confusion matrix\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)\n",
        "        plt.xticks(np.arange(class_count)+.5, classes, rotation=90)\n",
        "        plt.yticks(np.arange(class_count)+.5, classes, rotation=0)\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.title(\"Confusion Matrix\")\n",
        "        plt.show()\n",
        "    clr = classification_report(y_true, y_pred, target_names=classes, digits= 4) # create classification report\n",
        "    print(\"Classification Report:\\n----------------------\\n\", clr)\n",
        "    return errors, tests\n",
        "errors, tests=predictor(test_gen, test_steps)"
      ],
      "metadata": {
        "id": "sGLm6-04qkNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"results\"></a>\n",
        "# <center>Analysis of Model Performance\n",
        "In order to reduce training time the number of samples per class was limited to 150 images. We could have\n",
        "used the trim function with max_samples=198 to get better training accuracy. The image size of the original images\n",
        "was 600 X 600 but the model was trained with 200 X 200 images again to reduce training time. Overall the model\n",
        "did well with an average F1 score of 94.5 %. We ran for 12 epochs and the validation loss was still decreasing with\n",
        "about a 8% reduction in epoch 12. So we could run more epochs and probably acieve a better F1 score."
      ],
      "metadata": {
        "id": "emFijuz5UdZd"
      }
    }
  ]
}